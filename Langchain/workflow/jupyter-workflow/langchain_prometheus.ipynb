{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9ab15dc-a870-4d83-887a-5dce59d1e830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wikipedia in c:\\users\\euiyoung.hwang\\git_workspace\\vector_db_with_llm\\.venv\\lib\\site-packages (1.4.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\euiyoung.hwang\\git_workspace\\vector_db_with_llm\\.venv\\lib\\site-packages (from wikipedia) (4.12.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in c:\\users\\euiyoung.hwang\\git_workspace\\vector_db_with_llm\\.venv\\lib\\site-packages (from wikipedia) (2.27.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\euiyoung.hwang\\git_workspace\\vector_db_with_llm\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\euiyoung.hwang\\git_workspace\\vector_db_with_llm\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2024.8.30)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\euiyoung.hwang\\git_workspace\\vector_db_with_llm\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\euiyoung.hwang\\git_workspace\\vector_db_with_llm\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.10)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\euiyoung.hwang\\git_workspace\\vector_db_with_llm\\.venv\\lib\\site-packages (from beautifulsoup4->wikipedia) (2.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "''' Reference : https://gist.github.com/jcanizalez/e089e3ab8eaf119f8ee622cfa364ed8c '''\n",
    "# !pip install langchain-openai\n",
    "!pip install wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ab0bfa1-5012-446a-9206-e3366bb5f529",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\euiyoung.hwang\\Git_Workspace\\Vector_DB_with_LLM\\.venv\\Lib\\site-packages\\requests\\__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.20) or chardet (5.2.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from typing import Optional, Type\n",
    "from pydantic import BaseModel\n",
    "from langchain.tools import BaseTool\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce3e3d86-c2ba-4794-9ba2-f1dec3f2e555",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CURL_CA_BUNDLE'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6591956f-99ae-44b3-8e30-c21cc94363d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import BaseTool\n",
    "from typing import Optional\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.llms import HuggingFaceHub\n",
    "from langchain_huggingface import ChatHuggingFace, HuggingFacePipeline\n",
    "import requests\n",
    "\n",
    "from langchain.agents import (\n",
    "    AgentType, initialize_agent, load_tools\n",
    ")\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cc08439-e6fa-4086-ba7d-bed57de15d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrometheusQueryToolConfig(BaseModel):\n",
    "    prometheus_url: str = Field(default=\"http://localhost:9090\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8dd5672-9d36-41cb-b9c1-e2bbbfdf3c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomToolInput(BaseModel):\n",
    "    # query: str = Field()\n",
    "    query: Optional[str] = \"test\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "426da94b-ba0e-450f-8511-c8e9264e5cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrometheusQueryTool(BaseTool):\n",
    "    # name = \"Prometheus Query\"\n",
    "    # description = \"Tool for querying a Prometheus server\"\n",
    "    # config: Optional[PrometheusQueryToolConfig] = None\n",
    "    # args_schema: Type[BaseModel] = CustomToolInput\n",
    "    \n",
    "    def __init__(self, prometheus_url: str = \"http://localhost:9090\"):\n",
    "        # super().__init__()\n",
    "        # self.config = PrometheusQueryToolConfig(prometheus_url=prometheus_url)\n",
    "        # self.args_schema = {}\n",
    "        # self.args_schema: Type[BaseModel] = CustomToolInput\n",
    "        pass\n",
    "\n",
    "    def _run(self, query: str):\n",
    "        params = {'query': query}\n",
    "        response = requests.get(f\"{self.prometheus_url}/query\", params=params)\n",
    "        print(response.status_code)\n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        else:\n",
    "            return f\"Error: {response.text}\"\n",
    "\n",
    "    # def _arun(self, query: str):\n",
    "    #     raise NotImplementedError(\"This tool does not support async\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bf5b4e7-6314-4a3a-889c-73a17d908a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Prometheus Query Tool with the URL of your Prometheus server\n",
    "prometheus_tool = PrometheusQueryTool(prometheus_url=\"http://localhost:9090\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb94a9af-9eb2-47b9-b736-212cb3beb351",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize LLM (ChatOpenAI)\n",
    "# llm = ChatOpenAI(temperature=0, model_name='gpt-4')\n",
    "\n",
    "# model_id='mistralai/Mistral-7B-v0.1'\n",
    "model_id='HuggingFaceH4/zephyr-7b-beta'\n",
    "llm=HuggingFaceHub(repo_id=model_id, model_kwargs={\"temperature\": 0.2, \"max_length\": 1280})\n",
    "llm = ChatHuggingFace(llm=llm)\n",
    "\n",
    "# Include the Prometheus tool in the list of tools\n",
    "# tools = [prometheus_tool]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa2e0a62-1ccf-4e4c-b210-4d3d40ba1c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elasticsearch is a popular open-source search and analytics engine built on top of the Lucene library. It provides a distributed, RESTful search and analytics capability for unstructured and semi-structured data. Elasticsearch is designed to be scalable, resilient, and flexible, making it a popular choice for powering search and analytics use cases in various industries, such as e-commerce, logistics, finance, and healthcare. It offers features such as real-time index\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain import LLMChain\n",
    "\n",
    "# template = \"\"\"Answer in Korean.\n",
    "template = \"\"\"\n",
    "질문: {question}\n",
    "답변: \"\"\"\n",
    "# 프롬프트 템플릿 생성\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# LLM Chain 객체 생성\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "# question = \"what is the capital of korea?\"\n",
    "question = \"what is elasticsearch\"\n",
    "# print(llm_chain.run(question=question))\n",
    "# response = llm_chain.run(question=question)\n",
    "# print('\\nresponse\\n')\n",
    "# print(response)\n",
    "response = llm_chain.invoke(question)\n",
    "'''\n",
    "{'question': 'what is the capital of South Korea?', 'text': '<|user|>\\n질문: what is the capital of korea?\\n답변: </s>\\n<|assistant|>\\nThe capital of South Korea is Seoul, and the capital of North Korea is Pyongyang. However, in this context, if the question is referring to the entire Korean Peninsula, then there is no single capital as it is divided into two separate countries.'}\n",
    "'''\n",
    "print(response['text'].split('<|assistant|>')[1].strip())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca283f75-4767-440e-a7c1-13af6b2e4f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prompt for the agent\n",
    "prompt = \"\"\"\n",
    "Use metrics to answer this question:\n",
    "{text}\n",
    "\"\"\"\n",
    "\n",
    "# Initialize agent with tools\n",
    "# agent = initialize_agent(\n",
    "#     tools=tools,\n",
    "#     llm=llm,\n",
    "#     verbose=True,\n",
    "# )\n",
    "\n",
    "# agent = initialize_agent(\n",
    "#     tools=tools, llm=llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d9f80ce-50ab-4ade-b837-c46ee127e607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example query to the agent\n",
    "# response = agent(prompt.format(text=\"Can you check the status for all the pods in default namespace?\"))\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e859d21c-64d0-40f6-9339-78254c85d814",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
